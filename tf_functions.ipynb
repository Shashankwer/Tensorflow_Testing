{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_functions.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOmsqoMnJbO7UtUaDZ9nlyt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shashankwer/Tensorflow_Testing/blob/master/tf_functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtYZ7LNUUoBv",
        "colab_type": "text"
      },
      "source": [
        "In Tensorflow 2,eager execution is turned on by default. The user interface is intutive and flexible(running one of operation is much easier and faster). This can come at the expense of performance and deployability\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1jX0bAsUiov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Hs9fCnwU9fY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import traceback\n",
        "import contextlib"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DyddomAVAVu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@contextlib.contextmanager\n",
        "def assert_raises(error_class):\n",
        "  try:\n",
        "    yield\n",
        "  except error_class as e:\n",
        "    print('Caught excepted exception \\n {}'.format(error_class))\n",
        "    traceback.print_exc(limit=2)\n",
        "  except Exception as e:\n",
        "    raise e\n",
        "  else:\n",
        "    raise Exception('Expected {} to be raised but it was not raise'.format(error_class))\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdQ0sleEVrt5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d4e7150d-1083-43e8-8d5e-ca9579492574"
      },
      "source": [
        "@tf.function\n",
        "def add(a,b):\n",
        "  return a+b\n",
        "\n",
        "add(tf.ones([2,2]),tf.ones([2,2]))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              "array([[2., 2.],\n",
              "       [2., 2.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZFvy3erV7jU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "14e2577b-abd8-4a25-a400-2f04a2a10ad1"
      },
      "source": [
        "v = tf.Variable(1.0)\n",
        "with tf.GradientTape() as tape:\n",
        "  result = add(v,1.0)\n",
        "tape.gradient(result,v)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=1.0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0V6-VU8sWJj8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "436607d1-f9c3-4377-db39-ab2cfb8b8643"
      },
      "source": [
        "@tf.function\n",
        "def dense_layer(x,w,b):\n",
        "  return add(tf.matmul(x,w),b)\n",
        "\n",
        "dense_layer(tf.ones([3,2]),tf.ones([2,2]),tf.ones([2]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
              "array([[3., 3.],\n",
              "       [3., 3.],\n",
              "       [3., 3.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_RUSPh7WY-Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "77781ff0-31b7-4548-880e-51e75805e290"
      },
      "source": [
        "tf.matmul(tf.ones([3,2]),tf.ones([2,3]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
              "array([[2., 2., 2.],\n",
              "       [2., 2., 2.],\n",
              "       [2., 2., 2.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPP8hL_eWfPw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b8ffc809-f0c7-4437-b781-bf6a438c7f36"
      },
      "source": [
        "import timeit\n",
        "conv_layer = tf.keras.layers.Conv2D(100,3)\n",
        "\n",
        "@tf.function\n",
        "def conv_fn(image):\n",
        "  return conv_layer(image)\n",
        "\n",
        "image = tf.zeros([1,200,200,100])\n",
        "conv_layer(image);\n",
        "conv_fn(image)\n",
        "print(\"Eager conv :\",timeit.timeit(lambda: conv_layer(image),number=100))\n",
        "print(\"Function conv:\",timeit.timeit(lambda: conv_fn(image),number=100))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Eager conv : 14.921743999000228\n",
            "Function conv: 14.537456206000115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Oy_OLS6aHcs",
        "colab_type": "text"
      },
      "source": [
        "## Tracing: \n",
        "\n",
        "\n",
        "Python's dynamic typing means that one can call functions with a variety of argument types and a python can do something in each scenario. \n",
        "\n",
        "Yet to create Tensorflow Graph, static `dtypes` and shape dimension require `tf.function` bridges this gaps by wrapping a Python function to create a `Function` object. Based on the given inputs, the `Function` selects the appropriate graph for the given inputs retracing the python function as necessary. \n",
        "\n",
        "Once we understand why and when the tracing happends, it is much easier to use tf.function effectively. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGdn5fkMZhSp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "5eabc66a-5154-42e2-f888-060c0cb0bc19"
      },
      "source": [
        "@tf.function\n",
        "def double(a):\n",
        "  print(\"Tracing with \",a)\n",
        "  return a+a\n",
        "\n",
        "print(double(tf.constant(1)))\n",
        "print()\n",
        "print(double(tf.constant(1.1)))\n",
        "print()\n",
        "print(double(tf.constant(\"a\")))\n",
        "print()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tracing with  Tensor(\"a:0\", shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "\n",
            "Tracing with  Tensor(\"a:0\", shape=(), dtype=float32)\n",
            "tf.Tensor(2.2, shape=(), dtype=float32)\n",
            "\n",
            "Tracing with  Tensor(\"a:0\", shape=(), dtype=string)\n",
            "tf.Tensor(b'aa', shape=(), dtype=string)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUoc-Lwaj8Gc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d8d16766-e41a-4da5-bc19-d03c39152f3c"
      },
      "source": [
        "print(double(tf.constant(\"b\")))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'bb', shape=(), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWl-2dvmkI0_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "8b899920-3c94-4e96-9553-153fb54c1fe4"
      },
      "source": [
        "print(double.pretty_printed_concrete_signatures())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "double(a)\n",
            "  Args:\n",
            "    a: int32 Tensor, shape=()\n",
            "  Returns:\n",
            "    int32 Tensor, shape=()\n",
            "\n",
            "double(a)\n",
            "  Args:\n",
            "    a: string Tensor, shape=()\n",
            "  Returns:\n",
            "    string Tensor, shape=()\n",
            "\n",
            "double(a)\n",
            "  Args:\n",
            "    a: float32 Tensor, shape=()\n",
            "  Returns:\n",
            "    float32 Tensor, shape=()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upFW9qypkhGf",
        "colab_type": "text"
      },
      "source": [
        "The `tf.function` creates a chaced, dynamic dispatch layer over TensorFLow's graph tracing logic. TO be more specific about the terminology: \n",
        "\n",
        "1. A tf.Graph is the raw, language agnostic representation of the computation\n",
        "2. A concreteFunction is eagerly wrapped around a tf.Graph\n",
        "3. A function manages to cache ConcreteFunction and picks the right one for the inputs\n",
        "4. tf.function wraps a Python function and returns a python object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ol3KaPjDkUM1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "00f26a72-90f8-43bc-bbf3-68d6a42acd7c"
      },
      "source": [
        "double_strings = double.get_concrete_function(tf.constant(\"a\"))\n",
        "print(\"Excuting traces\")\n",
        "print(double_strings(tf.constant(\"a\")))\n",
        "print(double_strings(tf.constant(\"b\")))\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Excuting traces\n",
            "tf.Tensor(b'aa', shape=(), dtype=string)\n",
            "tf.Tensor(b'bb', shape=(), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGyAnqHEkZW4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "02bf944f-764e-4bd1-ad2a-8ce5a3d0a07e"
      },
      "source": [
        "double_strings_from_inputspec = double.get_concrete_function(tf.TensorSpec(shape=[],dtype=tf.string))\n",
        "print(double_strings_from_inputspec(tf.constant(\"c\")))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tracing with  Tensor(\"a:0\", shape=(), dtype=string)\n",
            "tf.Tensor(b'cc', shape=(), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJPr-Jdllli6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "3df84dae-6abb-42e9-df73-5d452c0c97a3"
      },
      "source": [
        "print(double_strings)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ConcreteFunction double(a)\n",
            "  Args:\n",
            "    a: string Tensor, shape=()\n",
            "  Returns:\n",
            "    string Tensor, shape=()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9puoHoVTlpLb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "57661206-c0ea-4833-f184-c6be1284f26a"
      },
      "source": [
        "print(double_strings.structured_input_signature)\n",
        "print(double_strings.structured_outputs)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "((TensorSpec(shape=(), dtype=tf.string, name='a'),), {})\n",
            "Tensor(\"Identity:0\", shape=(), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEl0RVOjl8cY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "36ae9547-5e19-4804-84e8-4578ea026331"
      },
      "source": [
        "with assert_raises(tf.errors.InvalidArgumentError):\n",
        "  double_strings(tf.constant(1))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Caught excepted exception \n",
            " <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-4-46ae65889eac>\", line 4, in assert_raises\n",
            "    yield\n",
            "  File \"<ipython-input-17-e4e2860a4364>\", line 2, in <module>\n",
            "    double_strings(tf.constant(1))\n",
            "tensorflow.python.framework.errors_impl.InvalidArgumentError: cannot compute __inference_double_625 as input #0(zero-based) was expected to be a string tensor but is a int32 tensor [Op:__inference_double_625]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9F5sh5-emFrE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "22fdf2fd-0b84-4943-f215-9df1f1981a43"
      },
      "source": [
        "@tf.function\n",
        "def pow(a,b):\n",
        "  return a**b\n",
        "\n",
        "square = pow.get_concrete_function(a=tf.TensorSpec(None,tf.float32),b=2)\n",
        "print(square)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ConcreteFunction pow(a, b=2)\n",
            "  Args:\n",
            "    a: float32 Tensor, shape=<unknown>\n",
            "  Returns:\n",
            "    float32 Tensor, shape=<unknown>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18NBWPHimcO9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "cbc80584-2d49-46ef-b73a-fd99d1cd0714"
      },
      "source": [
        "assert square(tf.constant(10.0))==100\n",
        "\n",
        "with assert_raises(TypeError):\n",
        "  square(tf.constant(10.0),b=3)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Caught excepted exception \n",
            " <class 'TypeError'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 1669, in _call_impl\n",
            "    cancellation_manager)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 1714, in _call_with_flat_signature\n",
            "    self._flat_signature_summary(), \", \".join(sorted(kwargs))))\n",
            "TypeError: pow(a) got unexpected keyword arguments: b.\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-4-46ae65889eac>\", line 4, in assert_raises\n",
            "    yield\n",
            "  File \"<ipython-input-19-77f1457582f0>\", line 4, in <module>\n",
            "    square(tf.constant(10.0),b=3)\n",
            "TypeError: ConcreteFunction pow(a, b) was constructed with int value 2 in b, but was called with int value 3\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elTvBSEomrnd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0ffd80d4-34b8-4f41-c371-41431c70f4ff"
      },
      "source": [
        "#Obtaining graphs\n",
        "\n",
        "graph  = double_strings.graph\n",
        "for node in graph.as_graph_def().node:\n",
        "  print(f'{node.input}->{node.name}')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]->a\n",
            "['a', 'a']->add\n",
            "['add']->Identity\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCBR5tzjne8X",
        "colab_type": "text"
      },
      "source": [
        "# Debugging\n",
        "\n",
        "In general, debugging code is easier in eager mode than inside `tf.function`. One should ensure that the code executes error free in eager mode befroe decorating with `tf.function`. To assist in the debugging process, one can call `tf.config.run_functions_eagerly(True)` to globally disable and reenable `tf.function`\n",
        "\n",
        "* Plain old print calls are executed when the tracking down the function is retraced \n",
        "* tf.print will execute every time\n",
        "* tf.debugging.enable_check_numerics is an easy way to track down where NaNs and Inf are created. \n",
        "* `pdb` can help one to understand whats going on during tracing\n",
        "\n",
        "\n",
        "# Tracing Semantics. \n",
        "\n",
        "## Cache rules: \n",
        "\n",
        "A `Function` determines whether to resue a traced concrete function by computing cache key from inputs arg and kwags\n",
        "\n",
        "* A key generated is in the form of tf.Tensor argument is its shape and dtype\n",
        "* Starting tensorflow 2.3, the key generated for a tf.Varaible argument is its id()\n",
        "* The key for a Python primitive is its value. The key generated for nested dicts, list and named tuples and attrs is the flattened tuple. \n",
        "* For all other Python types, the keys are based on the object id() so that the methods are traced independently from each other \n",
        "\n",
        "## Controlling retracing: \n",
        "\n",
        "Retracing helps to ensure that TensorFLow generates correct graphs for each of the inputs. However tracing is an expensive operation!. If ine Function retraces a new graph for eery call this would cause the function to trace more slowly than making use of `tf.function`\n",
        "\n",
        "To control the tracing behavior, one can use the following techniques\n",
        "\n",
        "* Specify the input signature in `tf.function` to limit tracing \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66z79pGFnGQs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "82600eb1-92ce-49eb-d364-e0b5e34ca5cf"
      },
      "source": [
        "@tf.function(input_signature=(tf.TensorSpec(shape=[None],dtype=tf.int32),))\n",
        "def next_collatz(x):\n",
        "  print(\"Tracing with\",x)\n",
        "  return tf.where(x%2==0,x//2,3*x+1)\n",
        "\n",
        "print(next_collatz(tf.constant([1,2])))\n",
        "\n",
        "with assert_raises(ValueError):\n",
        "  next_collatz(tf.constant([[1,2],[2,3]]))\n",
        "\n",
        "with assert_raises(ValueError):\n",
        "  next_collatz(tf.constant([1.0,2.0]))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tracing with Tensor(\"x:0\", shape=(None,), dtype=int32)\n",
            "tf.Tensor([4 1], shape=(2,), dtype=int32)\n",
            "Caught excepted exception \n",
            " <class 'ValueError'>\n",
            "Caught excepted exception \n",
            " <class 'ValueError'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-4-46ae65889eac>\", line 4, in assert_raises\n",
            "    yield\n",
            "  File \"<ipython-input-21-1e2b9d312016>\", line 9, in <module>\n",
            "    next_collatz(tf.constant([[1,2],[2,3]]))\n",
            "ValueError: Python inputs incompatible with input_signature:\n",
            "  inputs: (\n",
            "    tf.Tensor(\n",
            "[[1 2]\n",
            " [2 3]], shape=(2, 2), dtype=int32))\n",
            "  input_signature: (\n",
            "    TensorSpec(shape=(None,), dtype=tf.int32, name=None))\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-4-46ae65889eac>\", line 4, in assert_raises\n",
            "    yield\n",
            "  File \"<ipython-input-21-1e2b9d312016>\", line 12, in <module>\n",
            "    next_collatz(tf.constant([1.0,2.0]))\n",
            "ValueError: Python inputs incompatible with input_signature:\n",
            "  inputs: (\n",
            "    tf.Tensor([1. 2.], shape=(2,), dtype=float32))\n",
            "  input_signature: (\n",
            "    TensorSpec(shape=(None,), dtype=tf.int32, name=None))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ndugx2ZEZZV",
        "colab_type": "text"
      },
      "source": [
        "Specifying a [None] dimension in `tf.TensorSpec` to allow for flexibility in trace reuse\n",
        "\n",
        "Since Tensorflow matches tensors based on their shape, using a `None` dimension as a wildcard, it will allow `Function`s to reuse traces for variabley sized input or images of different size for each batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUbfk4PTEMMR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e0f1eeaf-7471-4809-9e4d-e26cef06ea2c"
      },
      "source": [
        "@tf.function(input_signature=(tf.TensorSpec(shape=[None],dtype=tf.int32),))\n",
        "def g(x):\n",
        "  print('Tracing with ',x)\n",
        "  return x\n",
        "\n",
        "print(g(tf.constant([1,2,3])))\n",
        "print(g(tf.constant([1,2,3,4,5])))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tracing with  Tensor(\"x:0\", shape=(None,), dtype=int32)\n",
            "tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n",
            "tf.Tensor([1 2 3 4 5], shape=(5,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDvAtSf0KU1W",
        "colab_type": "text"
      },
      "source": [
        "* Cast Python arguments to Tensors reducing the retracing: \n",
        "\n",
        "Often, Python arguments are used to controll the hyperparameters and graph constructions for example \n",
        "`num_layers=10` or `training=True` or `nonlinearity=relu`. So if the Python arguments changes, it makes sense that one would have to retrace the graph\n",
        "\n",
        "It is also possible that the argument is not used in graph construction. In these cases, a change in the Python value can trigger needless retracing. Despite the multiple traces, the generated graph is  actually identitcal thus retracing is unnecessary\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nTIlTKYFgxf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "a2dc846e-9c1b-495c-95bd-6ab628fe50e2"
      },
      "source": [
        "def train_one_step():\n",
        "  pass\n",
        "\n",
        "@tf.function\n",
        "def train(num_steps):\n",
        "  print(\"Tracing with num_steps=\",num_steps)\n",
        "  tf.print(\"Executing with num_steps = \",num_steps)\n",
        "  for _ in tf.range(num_steps):\n",
        "    train_one_step()\n",
        "\n",
        "print(\"Retracing occurs different for different python arguments\")\n",
        "train(num_steps=10)\n",
        "train(num_steps=20)\n",
        "\n",
        "print()\n",
        "print(\"Traces are reused for Tensor arguments.\")\n",
        "train(num_steps=tf.constant(10))\n",
        "train(num_steps=tf.constant(20))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Retracing occurs different for different python arguments\n",
            "Tracing with num_steps= 10\n",
            "Executing with num_steps =  10\n",
            "Tracing with num_steps= 20\n",
            "Executing with num_steps =  20\n",
            "\n",
            "Traces are reused for Tensor arguments.\n",
            "Tracing with num_steps= Tensor(\"num_steps:0\", shape=(), dtype=int32)\n",
            "Executing with num_steps =  10\n",
            "Executing with num_steps =  20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Izid_jV8MJeF",
        "colab_type": "text"
      },
      "source": [
        "If one needs a force retracing, the different versions of the functions will not be sharing traces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iT0VSYgL-go",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "4037cff1-ab18-4d3f-d88e-27a33e3cd9af"
      },
      "source": [
        "def f():\n",
        "  print('Tracing!')\n",
        "  print('Executing!!')\n",
        "\n",
        "tf.function(f)()\n",
        "tf.function(f)()  "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tracing!\n",
            "Executing!!\n",
            "Tracing!\n",
            "Executing!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qR9P5EsCMYmp",
        "colab_type": "text"
      },
      "source": [
        "## Python side effects: \n",
        "\n",
        "Python side effects like printing, appending to list and mutating globals only happens the first time one calls the function. The graph is constructed in the first run. `tf.Graph` is reexecuted, without executing the Python code.\n",
        "\n",
        "The general rule of thumb is to only use Python side effects to debug your traces. Otherwise tf.Variable.assign, tf.print, and tf.summary are the best way for retracing during tensorflow runtime"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIdkRavjMVC1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "af8e9f6e-de06-4cf1-a929-be56770e2eb6"
      },
      "source": [
        "@tf.function\n",
        "def f(x):\n",
        "  print(\"Traced with\",x)\n",
        "  tf.print(\"Executed with\",x)\n",
        "f(1)\n",
        "f(1)\n",
        "f(2)\n",
        "f(tf.constant(1))\n",
        "f(tf.constant(2))\n",
        "f(tf.constant(3))\n",
        "f(tf.constant(4))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traced with 1\n",
            "Executed with 1\n",
            "Executed with 1\n",
            "Traced with 2\n",
            "Executed with 2\n",
            "Traced with Tensor(\"x:0\", shape=(), dtype=int32)\n",
            "Executed with 1\n",
            "Executed with 2\n",
            "Executed with 3\n",
            "Executed with 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kHXGFTBNVgr",
        "colab_type": "text"
      },
      "source": [
        "A generator might be used for keeping track of the states. This works well in eager mode execution. The same result might not work well in the function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LF_OOUL6NDo-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9e85d894-9d2e-4736-f3c1-fd7e711aef74"
      },
      "source": [
        "external_var = tf.Variable(0)\n",
        "@tf.function\n",
        "def buggy_consume_next(iterator):\n",
        "  external_var.assign_add(next(iterator))\n",
        "  tf.print(\"Value of external_var:\",external_var)\n",
        "\n",
        "iterator = iter([0,1,2,3,4])\n",
        "buggy_consume_next(iterator)\n",
        "\n",
        "buggy_consume_next(iterator)\n",
        "buggy_consume_next(iterator)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Value of external_var: 0\n",
            "Value of external_var: 0\n",
            "Value of external_var: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33n5bddlOIz_",
        "colab_type": "text"
      },
      "source": [
        "If one would like to execute a python code during invokation of a Function `tf.py_function` is an exit hatch. The drawback of `tf.py_function` is that its not portable or particularly performat, nor does it works well with distribution setups. Also since tf.py_function has to be wired into graphs, it casts all inputs/outputs to tensors\n",
        "\n",
        "APIs like tf.gather, tf.stack and tf.TensorArray can help one to implement common looping patterns in native Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "si5cIONOOIep",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "636a9944-f7b5-43fa-a94d-b61f97bf3761"
      },
      "source": [
        "external_list= []\n",
        "\n",
        "def side_effect(x):\n",
        "  print(\"Python side effects\")\n",
        "  external_list.append(x)\n",
        "\n",
        "@tf.function\n",
        "def f(x):\n",
        "  tf.py_function(side_effect,inp=[x],Tout=[])\n",
        "\n",
        "f(1)\n",
        "f(1)\n",
        "f(1)\n",
        "\n",
        "assert len(external_list) == 3\n",
        "assert external_list[0].numpy() == 1"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python side effects\n",
            "Python side effects\n",
            "Python side effects\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itWBu80pPSMt",
        "colab_type": "text"
      },
      "source": [
        "### Variables: \n",
        "\n",
        "One may encounter an error when creating a new `tf.Variable` in a function. This error guards against the behavior of divergence on repeated calls. In eager mode the varaible is created on every call. In function mode the variable may not be created due to common retracing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OS1ciFzcN3UH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def f(x):\n",
        "  v = tf.Variable(1.0)\n",
        "  v.assign_add(x)\n",
        "  return v\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRvVBH-IPHvt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "7d286017-cf51-410a-b3a3-7f31f32d3fa6"
      },
      "source": [
        "with assert_raises(ValueError):\n",
        "  f(1.0)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Caught excepted exception \n",
            " <class 'ValueError'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-4-46ae65889eac>\", line 4, in assert_raises\n",
            "    yield\n",
            "  File \"<ipython-input-29-393b338b5a82>\", line 2, in <module>\n",
            "    f(1.0)\n",
            "ValueError: in user code:\n",
            "\n",
            "    <ipython-input-28-9ce361fb3439>:3 f  *\n",
            "        v = tf.Variable(1.0)\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py:262 __call__  **\n",
            "        return cls._variable_v2_call(*args, **kwargs)\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py:256 _variable_v2_call\n",
            "        shape=shape)\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py:67 getter\n",
            "        return captured_getter(captured_previous, **kwargs)\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py:702 invalid_creator_scope\n",
            "        \"tf.function-decorated function tried to create \"\n",
            "\n",
            "    ValueError: tf.function-decorated function tried to create variables on non-first call.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDphDBJbP6cU",
        "colab_type": "text"
      },
      "source": [
        "Variable can be created inside the function as long as those variables are only created the first time the function is executed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGRGby_hPxFL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "08996c4b-ded4-4dad-c02e-f6a66835aa36"
      },
      "source": [
        "class Count(tf.Module):\n",
        "  def __init__(self):\n",
        "    self.count = None\n",
        "  \n",
        "  @tf.function\n",
        "  def __call__(self):\n",
        "    if self.count is None:\n",
        "      self.count = tf.Variable(0)\n",
        "    return self.count.assign_add(1)\n",
        "\n",
        "c = Count()\n",
        "print(c())\n",
        "print(c())\n",
        "print(c())\n",
        "print(c())"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(1, shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "tf.Tensor(3, shape=(), dtype=int32)\n",
            "tf.Tensor(4, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8RBGa_KQabO",
        "colab_type": "text"
      },
      "source": [
        "Another error one might encounter is the garbage collected variable. Unlimke normal Python functions, these function only retrain WeakRefs to the variables they close over, one must retain a reference to any variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUXckQKNQUe6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "1a81a4cd-6546-43ba-cbb6-67378d4402a1"
      },
      "source": [
        "external_var = tf.Variable(3)\n",
        "@tf.function\n",
        "def f(x):\n",
        "  return x*external_var\n",
        "\n",
        "trace_f = f.get_concrete_function(4)\n",
        "print(\"Calling concrete function\")\n",
        "print(trace_f(4))\n",
        "\n",
        "del external_var\n",
        "print()\n",
        "print(\"Calling concrete function after the garbage collection its  weakly referenced variable\")\n",
        "with assert_raises(tf.errors.FailedPreconditionError):\n",
        "  trace_f(4)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calling concrete function\n",
            "tf.Tensor(12, shape=(), dtype=int32)\n",
            "\n",
            "Calling concrete function after the garbage collection its  weakly referenced variable\n",
            "Caught excepted exception \n",
            " <class 'tensorflow.python.framework.errors_impl.FailedPreconditionError'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-4-46ae65889eac>\", line 4, in assert_raises\n",
            "    yield\n",
            "  File \"<ipython-input-31-08ec80324c16>\", line 14, in <module>\n",
            "    trace_f(4)\n",
            "tensorflow.python.framework.errors_impl.FailedPreconditionError:  Error while reading resource variable _AnonymousVar4 from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/_AnonymousVar4/N10tensorflow3VarE does not exist.\n",
            "\t [[node ReadVariableOp (defined at <ipython-input-31-08ec80324c16>:4) ]] [Op:__inference_f_979]\n",
            "\n",
            "Function call stack:\n",
            "f\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYZAhZfSRLeK",
        "colab_type": "text"
      },
      "source": [
        "# AutoGraph Transformations\n",
        "\n",
        "Autograph is a library is on by default in `tf.function`, and transforms a subset of Python eager code into graph compatible tensorflow ops. This includes control flows like `if`,`for` and `while`\n",
        "\n",
        "Tensorflow ops like `tf.cond` and `tf.while_loop` continue to work, but control flow easier to write and understand in Python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mea5zCqzRHVw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "06348890-71f1-4b1a-9230-1f7da82ae837"
      },
      "source": [
        "#Simple loop\n",
        "\n",
        "@tf.function\n",
        "def f(x):\n",
        "  while tf.reduce_sum(x)>1:\n",
        "    tf.print(x)\n",
        "    x = tf.tanh(x)\n",
        "  return x\n",
        "\n",
        "f(tf.random.uniform([5]))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.664173365 0.969144344 0.879497886 0.0735514164 0.600046515]\n",
            "[0.581134081 0.74832803 0.706167758 0.0734190643 0.537082672]\n",
            "[0.523489237 0.634150445 0.608268082 0.0732874274 0.490776539]\n",
            "[0.480388522 0.560903549 0.542906821 0.0731564909 0.454832554]\n",
            "[0.44655472 0.508647501 0.495185167 0.0730262548 0.425863236]\n",
            "[0.419062912 0.468890727 0.458322108 0.0728967115 0.401858389]\n",
            "[0.396140695 0.437302619 0.428715676 0.0727678537 0.381537914]\n",
            "[0.376641959 0.4114061 0.404247433 0.0726396814 0.364042312]\n",
            "[0.359787643 0.389665931 0.383577347 0.0725121871 0.348769635]\n",
            "[0.34502697 0.371072173 0.365810156 0.0723853558 0.335283905]\n",
            "[0.331957847 0.354929149 0.350321501 0.0722591802 0.323260576]\n",
            "[0.320278883 0.340739667 0.336660624 0.0721336678 0.312452137]\n",
            "[0.309759051 0.328137577 0.324492872 0.0720088184 0.302666247]\n",
            "[0.300217867 0.316846281 0.313563734 0.0718846098 0.293750703]\n",
            "[0.291511953 0.306652516 0.303675652 0.0717610344 0.285583287]\n",
            "[0.283525795 0.297388703 0.294672728 0.0716381 0.278064609]\n",
            "[0.276165098 0.288921088 0.286429882 0.0715157911 0.271112889]\n",
            "[0.269352049 0.28114149 0.278845549 0.0713941082 0.26466006]\n",
            "[0.263021797 0.273961186 0.271836251 0.0712730438 0.258649051]\n",
            "[0.257119715 0.267306864 0.265332609 0.0711526 0.253031492]\n",
            "[0.25159952 0.261117101 0.259276479 0.0710327551 0.247766182]\n",
            "[0.246421635 0.255340099 0.253618658 0.0709135234 0.242817685]\n",
            "[0.241552 0.249931812 0.248317227 0.0707948878 0.238155395]\n",
            "[0.236961141 0.24485454 0.243336171 0.0706768483 0.233752668]\n",
            "[0.232623369 0.240075767 0.238644421 0.0705594 0.229586244]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
              "array([0.2285162 , 0.2355673 , 0.23421493, 0.07044253, 0.22563568],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fc6TSaE9SsrK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "aced947d-cd20-47d9-c070-aeb745b40a3e"
      },
      "source": [
        "print(tf.autograph.to_code(f.python_function))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "def tf__f(x):\n",
            "    with ag__.FunctionScope('f', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
            "        do_return = False\n",
            "        retval_ = ag__.UndefinedReturnValue()\n",
            "\n",
            "        def get_state():\n",
            "            return (x,)\n",
            "\n",
            "        def set_state(vars_):\n",
            "            nonlocal x\n",
            "            (x,) = vars_\n",
            "\n",
            "        def loop_body():\n",
            "            nonlocal x\n",
            "            ag__.converted_call(ag__.ld(tf).print, (ag__.ld(x),), None, fscope)\n",
            "            x = ag__.converted_call(ag__.ld(tf).tanh, (ag__.ld(x),), None, fscope)\n",
            "\n",
            "        def loop_test():\n",
            "            return (ag__.converted_call(ag__.ld(tf).reduce_sum, (ag__.ld(x),), None, fscope) > 1)\n",
            "        ag__.while_stmt(loop_test, loop_body, get_state, set_state, ('x',), {})\n",
            "        try:\n",
            "            do_return = True\n",
            "            retval_ = ag__.ld(x)\n",
            "        except:\n",
            "            do_return = False\n",
            "            raise\n",
            "        return fscope.ret(retval_, do_return)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qRoTcXNTE0m",
        "colab_type": "text"
      },
      "source": [
        "## Conditionals:\n",
        "\n",
        "Autograph will convert some `if<condition>` statement into its equivalent `tf.cond` calls. This substitution is made if `<condition>` is a Tensor. Otherwise `if` statement is executed as a Python conditional\n",
        "\n",
        "A Python conditional executes during tracing, so exactly one branch of the conditional will be aded to the graph. Without AutoGraph, this traced graph would be unable to take the alternative branch if there is data-dependent control flow. \n",
        "\n",
        "`tf.cond` traces and adds both branches of the conditional to the graph, dynamically selecting a branch at execution time. Tracing can have unintended side effects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fuu9TOasS0-H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "906cca69-24a5-44d6-d966-eb9e444434b0"
      },
      "source": [
        "@tf.function\n",
        "def fizzbuzz(n):\n",
        "  for i in tf.range(1, n+1):\n",
        "    print('Tracing for loop')\n",
        "    if i%15==0:\n",
        "      print('Tracing fizzbuzz branch')\n",
        "      tf.print('fizzbuzz')\n",
        "    elif i%3 ==0:\n",
        "      print('Tracing fizz branch')\n",
        "      tf.print('fizz')\n",
        "    elif i%5 ==0:\n",
        "      print('Tracing buzz branch')\n",
        "      tf.print('buzz')\n",
        "    else:\n",
        "      print('Testing default branch')\n",
        "      tf.print(i)\n",
        "\n",
        "fizzbuzz(tf.constant(5))\n",
        "fizzbuzz(tf.constant(30))\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tracing for loop\n",
            "Tracing fizzbuzz branch\n",
            "Tracing fizz branch\n",
            "Tracing buzz branch\n",
            "Testing default branch\n",
            "1\n",
            "2\n",
            "fizz\n",
            "4\n",
            "buzz\n",
            "1\n",
            "2\n",
            "fizz\n",
            "4\n",
            "buzz\n",
            "fizz\n",
            "7\n",
            "8\n",
            "fizz\n",
            "buzz\n",
            "11\n",
            "fizz\n",
            "13\n",
            "14\n",
            "fizzbuzz\n",
            "16\n",
            "17\n",
            "fizz\n",
            "19\n",
            "buzz\n",
            "fizz\n",
            "22\n",
            "23\n",
            "fizz\n",
            "buzz\n",
            "26\n",
            "fizz\n",
            "28\n",
            "29\n",
            "fizzbuzz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erDeqBeKUs3N",
        "colab_type": "text"
      },
      "source": [
        "### Loops:\n",
        "\n",
        "Autograph will convert some `for` and `while` statements into the equivlen Tensorflow loops ops, like tf.while_loop. If not converted, the for or while loop is executed as a Python loop. \n",
        "\n",
        "This substitution is made in the following situations\n",
        "\n",
        "* `for x in y`: if `y` is a Tensor, convert to `tf.while_loop`. In the special case where `y` is a `tf.data.Dataset`, combination of `tf.data.Dataset` ops are generated\n",
        "* while `<condition>`: if `<condition>` is a Tensor, convert to `tf.while_loop`\n",
        "\n",
        "A python loop executes during tracing and adding the additional ops to the `tf.Graph`. for every iteration of the loop. \n",
        "\n",
        "A Tensorflow loop traces the body of the loop and dynamically selects how many Iterations to run at execution time. The loop body only executes once in `tf.Graph`\n",
        "\n",
        "\n",
        "A common pitfall is looping over python/numpy data in function `tf.function`. This loop will run during the plotting process, adding a copy of your model to `tf.Graph` for each iteration\n",
        "\n",
        "If we want the `tf.function` whole training loop in `tf.function`,the safest way to do that is to have `tf.data.Dataset` so that AutoGraph dunamically unwinds the training loop.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRBZHe6tUcib",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "67b81384-3128-4a6e-9318-2996a83c220b"
      },
      "source": [
        "def measure_graph_size(f,*args):\n",
        "  g = f.get_concrete_function(*args).graph\n",
        "  print(\"{} {} contains {} nodes in its graph\".format(f.__name__,', '.join(map(str,args)),len(g.as_graph_def().node)))\n",
        "\n",
        "@tf.function\n",
        "def train(dataset):\n",
        "  loss = tf.constant(0)\n",
        "  for x,y in dataset:\n",
        "    loss+= tf.abs(y-x)\n",
        "  return loss\n",
        "\n",
        "small_data = [(1,1)]*3\n",
        "big_data = [(1,1)]*10\n",
        "measure_graph_size(train,small_data)\n",
        "measure_graph_size(train,big_data)\n",
        "\n",
        "measure_graph_size(train,tf.data.Dataset.from_generator(lambda:small_data,(tf.int32,tf.int32)))\n",
        "measure_graph_size(train,tf.data.Dataset.from_generator(lambda:big_data,(tf.int32,tf.int32)))\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train [(1, 1), (1, 1), (1, 1)] contains 11 nodes in its graph\n",
            "train [(1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1)] contains 32 nodes in its graph\n",
            "train <FlatMapDataset shapes: (<unknown>, <unknown>), types: (tf.int32, tf.int32)> contains 8 nodes in its graph\n",
            "train <FlatMapDataset shapes: (<unknown>, <unknown>), types: (tf.int32, tf.int32)> contains 8 nodes in its graph\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsU_a5cn6WKq",
        "colab_type": "text"
      },
      "source": [
        "When we wrap Python/Numpy data in a dataset, relative to. The former, will keep the data in Python and retrieve it via which may have performance implications, while the latter will aggregate a copy of the data as a large node in the graph, which may have implication for performance on memory. `tf.data.Dataset.from_generator`\n",
        "`tf.data.Dataset.from_tensors`\n",
        "\n",
        "Reading data from files via TFRecordDataset/CsvDataset/ etc is the most efficient way to consume the data and does not involve data loading or prefeteching using Python. \n",
        "\n",
        "## Accumulating values in a loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eK55O1Lt1oXn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "ffcfeb23-bcd5-4fd4-ca2e-a68543aed0a0"
      },
      "source": [
        "batch_size =2\n",
        "seq_len  = 3\n",
        "feature_size = 4\n",
        "\n",
        "def rnn_step(inp,state):\n",
        "  return inp + state\n",
        "\n",
        "@tf.function\n",
        "def dynamic_rnn(rnn_step,input_data,initial_state):\n",
        "  input_data = tf.transpose(input_data,[1,0,2])\n",
        "  max_seq_len = input_data.shape[0]\n",
        "\n",
        "  states = tf.TensorArray(tf.float32,size=max_seq_len)\n",
        "  state = initial_state\n",
        "  for i in tf.range(max_seq_len):\n",
        "    state = rnn_step(input_data[i],state)\n",
        "    states = states.write(i,state)\n",
        "  return tf.transpose(states.stack(),[1,0,2])\n",
        "\n",
        "dynamic_rnn(rnn_step,tf.random.uniform([batch_size,seq_len,feature_size]),\n",
        "            tf.zeros([batch_size,feature_size])\n",
        "            )\n",
        "\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3, 4), dtype=float32, numpy=\n",
              "array([[[0.7389803 , 0.25470185, 0.61482334, 0.99299073],\n",
              "        [1.2608832 , 0.56535447, 0.7802501 , 1.2835064 ],\n",
              "        [1.7465137 , 0.71508026, 0.9849535 , 1.5519809 ]],\n",
              "\n",
              "       [[0.9971254 , 0.1277901 , 0.17888403, 0.94876456],\n",
              "        [1.3096862 , 0.40042984, 0.7757361 , 1.0846279 ],\n",
              "        [2.244003  , 1.0542338 , 1.3096174 , 1.1859447 ]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "936QdBsk720a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}